{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5efe8c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validating analytic workflows\n",
    "\n",
    "In this notebook we will show how to use simulations and create synthetic data to validate an analysis workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import balanced_accuracy_score, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.image import smooth_img, index_img, resample_to_img\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.datasets import (\n",
    "    fetch_atlas_difumo,\n",
    "    load_mni152_brain_mask,\n",
    "    load_mni152_template\n",
    ")\n",
    "import nilearn.plotting\n",
    "import nibabel as nib\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05f69e-6ae8-49fe-88fb-0a87759c194b",
   "metadata": {},
   "source": [
    "### Generating synthetic neuroimaging data\n",
    "\n",
    "It can be useful to benchmark analyses using synthetic data before ever applying them to real data.  In the best case, one would actually pre-register the analyses developed on synthetic data prior applying them to real data.\n",
    "\n",
    "Let's say that we wanted to test a new \"biomarker\" for depression using task fMRI.  We could start by generating some random data (using the MNI305 mask as our starting point) and then apply our new technique to that, either using a completely random value for diagnostic category, or creating the diagnostic category to have a specific relationship to the synthetic brain data.\n",
    "\n",
    "First, we can set up a [`NiftiMasker`](https://nilearn.github.io/stable/modules/generated/nilearn.maskers.NiftiMasker.html) based on the MNI305 mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637b2ab-0acf-4bb1-ba99-b5be8d76c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnimask = load_mni152_brain_mask(resolution=3.)\n",
    "mnitemplate = load_mni152_template(resolution=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441a2e9-3888-4a36-9412-47dfa694b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = nilearn.plotting.plot_anat(mnitemplate)\n",
    "disp.add_overlay(mnimask, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060459-da71-40cd-8dd5-56978b588088",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()\n",
    "maskdata = masker.fit_transform(mnimask)\n",
    "maskdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be70fe-eda0-4130-9289-b6783b8dbf3a",
   "metadata": {},
   "source": [
    "We then generate random Gaussian data for each subject (let's say 100 subjects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837fdd2-f990-4f1a-bfe1-089fc7eedb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_img(maskimg, nsubs=100, seed=None, fwhm=8):\n",
    "    masker = NiftiMasker()\n",
    "    maskdata = masker.fit_transform(maskimg)\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    syndata = rng.normal(size=(nsubs, maskdata.shape[1]))\n",
    "    synimg = masker.inverse_transform(syndata)\n",
    "    if fwhm is not None:\n",
    "        synimg = smooth_img(synimg, 8)\n",
    "    return synimg, masker\n",
    "\n",
    "synimg, masker = generate_noise_img(mnimask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7363c1a-1b66-46be-b13f-c50cc620f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nilearn.plotting.plot_img(index_img(synimg, 1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782f3fd-116b-49da-9906-f02de106e21e",
   "metadata": {},
   "source": [
    "### Testing our biomarker\n",
    "\n",
    "Now let's test our biomarker.  Our innovation is to implement a feature selection procedure called \"Select K best\" to reduce the dimensionality of the data for the prediction model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14a6bc-5086-4a24-9364-9b51216f5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_biomarker_model(img, y, mask, nfeatures=50, n_splits=20, \n",
    "                         seed=None, shuffle_y=False, fsel='outside'):\n",
    "    # Validate parameters.\n",
    "    assert fsel is None or fsel in ('inside', 'outside')\n",
    "    assert y.shape[0] == img.shape[-1]\n",
    "\n",
    "    # Extract masked data.\n",
    "    masker = NiftiMasker(mask)\n",
    "    maskdata = masker.fit_transform(img)\n",
    "    \n",
    "    # Shuffle y if requested.\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if shuffle_y:\n",
    "        y = y.copy()\n",
    "        np.random.shuffle(y)\n",
    "\n",
    "    # Select K best features from the entire dataset (outside of train/test split).\n",
    "    if fsel == 'outside':\n",
    "        selector = SelectKBest(f_classif, k=nfeatures)\n",
    "        X = selector.fit_transform(maskdata, y)\n",
    "    else:\n",
    "        X = maskdata    \n",
    "\n",
    "    clf = LinearSVC()\n",
    "    scores = []\n",
    "    for _ in range(n_splits):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rng)\n",
    "\n",
    "        # Select K best features from the training set alone.\n",
    "        if fsel == 'inside':\n",
    "            selector = SelectKBest(f_classif, k=nfeatures)\n",
    "            X_train = selector.fit_transform(X_train, y_train)\n",
    "            X_test = selector.transform(X_test)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        balanced_score = balanced_accuracy_score(y_test, y_pred)\n",
    "        scores.append(balanced_score)\n",
    "    return np.mean(scores)\n",
    "    \n",
    "rng = np.random.RandomState(1)\n",
    "prevalence = 0.5\n",
    "diag = (rng.uniform(size=synimg.shape[-1]) > prevalence).astype('int')\n",
    "\n",
    "train_biomarker_model(synimg, diag, mnimask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c697336-73b6-4c88-9069-608b79becbb2",
   "metadata": {},
   "source": [
    "If we didn't know that there was no true relationship between the brain data and diagnosis in this dataset, we wouldn't realize that this above-chance classification accuracy was weird. We would likely want to know whether the observed accuracy score is sufficiently larger than what one would expect under the null hypothesis of no predictive relationship (i.e. 50%). To determine this, we can run the model repeatedly while shuffling the order of the y variable, which essentially breaks the relationship on average between the X and y variables. In principle, this should have a balanced accuracy of 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f6867-eba3-46f1-9630-f16deb3395a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "nsimruns = 50\n",
    "\n",
    "progbar = IntProgress(min=0, max=nsimruns) # instantiate the bar\n",
    "display(progbar) # display the bar\n",
    "for _ in range(nsimruns):\n",
    "    progbar.value += 1\n",
    "    scores.append(train_biomarker_model(synimg, diag, mnimask, shuffle_y=True))\n",
    "print(np.mean(scores))\n",
    "plt.hist(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d12ab-17d9-4fc3-950d-83fda6e7fd3e",
   "metadata": {},
   "source": [
    "Wait, what? The accuracy scores are all well above 50% even when we shuffle the data, which means that there must be some kind of leaking of information from the test data into the training. In this case, it's due to the fact that our feature selection procedure was applied on the entire dataset prior to cross-validation, rather than within the cross-validation. If we move the feature selection step inside the cross-validation loop, we should see that the predictive accuracy decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d636-811e-42fd-9232-027d39de416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_biomarker_model(synimg, diag, mnimask, fsel='inside')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08322f92-3c8c-4cff-9217-9a58ab125ea5",
   "metadata": {},
   "source": [
    "This example shows how injecting synthetic data into our analysis procedures can help ensure that they are not providing us with biased results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d56e22-5f48-40cd-b9ae-d41d2a9665ed",
   "metadata": {},
   "source": [
    "### Generating realistic signals for testing\n",
    "\n",
    "In the previous example we tested whether our procedure effectively controls for false positive results. In other cases, we may also want to know the degree to which our analysis procedure can accurately detect signals when they exist (often known as \"parameter recovery\"). To assess this, we need to generate synthetic data that contains both realistic signal and realistic noise, and then apply our procedure to assess its effectiveness.\n",
    "\n",
    "Here we will inject some true signal relating activity to age into one of the regions of the brain, and then assess how well different methods can detect the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7224b5-5c36-4ce5-bf9b-c2517bf6f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "difumo = fetch_atlas_difumo(resolution_mm=2, legacy_format=False)\n",
    "difumo_maps = nib.load(difumo['maps'])\n",
    "# use component 63, which includes bilateral caudate\n",
    "# first resample the difumo image to the same space as the data (which is the 3mm mni space)\n",
    "roi_img = resample_to_img(index_img(difumo_maps, 63), mnitemplate)\n",
    "disp = nilearn.plotting.plot_stat_map(roi_img, bg_img=mnitemplate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0d3aa-1b22-473e-b7e3-bc14f8de2f1f",
   "metadata": {},
   "source": [
    "Now let's generate some data by injecting signal into those masked voxels relating their activity to age.\n",
    "\n",
    "Generate Gaussian noise, and then add signal within ROI voxels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3aa3c-cb65-41d2-ad25-e29535402d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(roi_img, beta=10):\n",
    "    synimg, masker = generate_noise_img(mnimask)\n",
    "    syndata = masker.transform(synimg)\n",
    "    roidata = np.repeat(masker.transform(roi_img), syndata.shape[0], 0)\n",
    "\n",
    "    diag = rng.normal(size=syndata.shape[0]) > 0\n",
    "    diagdata = np.repeat(diag[:, np.newaxis], roidata.shape[1], 1)\n",
    "\n",
    "    return syndata + roidata * diagdata * beta, diag\n",
    "\n",
    "simdata, diag = generate_synthetic_data(roi_img, beta=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b43ca-7263-4c7d-aa25-eddf975731ac",
   "metadata": {},
   "source": [
    "Fit linear regression to confirm that signal injection worked:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624bfdc-0e0e-41e8-8875-8c90abad9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "_ = lr.fit(simdata, diag)\n",
    "coef_img = masker.inverse_transform(lr.coef_)\n",
    "cut_coords = [13, 14, 1]\n",
    "nilearn.plotting.plot_stat_map(coef_img, bg_img=mnitemplate, threshold=.01, cut_coords=cut_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ef410-58d0-40c6-a409-6c073262c6e5",
   "metadata": {},
   "source": [
    "Let's say that we are interested in trying several different predictive methods to assess their ability to accurately estimate age in a new sample, and to identify the relevant voxels in the brain that support this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443db8d-6183-43eb-a1ca-a3419074c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try halving grid search to find optimal parameters\n",
    "\n",
    "models = {\n",
    "          'svm': LinearSVC(),\n",
    "          'enet': SGDClassifier(penalty='elasticnet'),\n",
    "         }\n",
    "param_grid = {\n",
    "    'svm': {\n",
    "        'C': [0.1, 0.5, 1, 10, 25, 50, 100, 500, 1000, 10000]\n",
    "    },   \n",
    "    'enet': {\n",
    "        'alpha': np.arange(0.1, 0.9, 0.2), \n",
    "        'l1_ratio': np.arange(0.1, 0.95, 0.2)\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def run_cv(simdata, diag, models, param_grid, seed=None, n_splits=20):\n",
    "\n",
    "    scores = defaultdict(list)\n",
    "    coefs = defaultdict(list)\n",
    "    best_params = defaultdict(list)\n",
    "\n",
    "    y = diag.copy()\n",
    "        \n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    for model, clf in models.items():\n",
    "        print(f'Running {model}...')\n",
    "        progbar = IntProgress(min=0, max=n_splits) # instantiate the bar\n",
    "        display(progbar) # display the bar\n",
    "\n",
    "\n",
    "        for _ in range(n_splits):\n",
    "            progbar.value += 1\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                simdata, y, test_size=0.25, random_state=rng\n",
    "            )\n",
    "            if model in param_grid:\n",
    "                gsh = HalvingGridSearchCV(\n",
    "                    estimator=clf, param_grid=param_grid[model], factor=2, random_state=rng\n",
    "                )\n",
    "                gsh.fit(X_train, y_train)\n",
    "                clf.set_params(**gsh.best_params_)\n",
    "                best_params[model].append(gsh.best_params_)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            scores[model].append(balanced_accuracy_score(y_test, y_pred))\n",
    "            coefs[model].append(clf.coef_)\n",
    "        mean_score = np.mean(scores[model])\n",
    "        print(f'Mean r-squared for {model}: {mean_score}\\n')\n",
    "\n",
    "    return coefs, scores, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acfbb3-5c3a-4c60-9b1a-e544147fbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs, scores, best_params = run_cv(simdata, diag, models, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ae7e0-99dc-4112-8189-3e669135cb37",
   "metadata": {},
   "source": [
    "A simple way to look at the stability of the support for each classifier is to identify voxels with significant positive coefficient values across the cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ea99e-dad9-4bf9-b852-c40f9750960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_img = {}\n",
    "t = {}\n",
    "meancoef = {}\n",
    "\n",
    "for model, coeflist in coefs.items():\n",
    "    if coeflist == []:\n",
    "        print('no coefs for', model)\n",
    "        continue\n",
    "    meancoef[model] = np.mean(coeflist, axis=0)\n",
    "    stderr = np.std(coeflist, axis=0, ddof=1) / np.sqrt(len(coeflist))\n",
    "    t[model] = np.nan_to_num(meancoef[model] / stderr)\n",
    "    t_img[model] = masker.inverse_transform(t[model])\n",
    "    t_img_thresh, threshold = threshold_stats_img(\n",
    "        t_img[model], height_control='fdr', alpha=.01, cluster_threshold=20\n",
    "    )\n",
    "    # t_img[model].to_filename(f'{model}_tstat.nii.gz')\n",
    "    nilearn.plotting.plot_stat_map(t_img_thresh, bg_img=mnitemplate, \n",
    "                                   cut_coords=cut_coords, threshold=threshold, \n",
    "                                   title=model, symmetric_cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c867ef3-d02a-4ac2-8ff7-d4c0d2d53e9e",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "We would also like to check that there is no leakage in our cross-validation scheme, by testing the performance of the model when the outcome variable is shuffled. \n",
    "\n",
    "1. Modify the `run_cv()` function above to include a `shuffle_y` flag with a default value of `False`, and add code that will shuffle the y variable if this flag is set to true.  The following code should execute successfully if you have done this properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2c515-8328-4ffe-88d9-f511bd888bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, scores_shuf, _ = run_cv(simdata, diag, models, param_grid, shuffle_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a38207-3766-4e6d-a076-39b1af823de0",
   "metadata": {},
   "source": [
    "Use the `scores_shuf` output from the previous step to check whether the average accuracy value for each model falls between 0.475 and 0.525."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e2d56-74cb-4e01-b899-53508c1ef6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in scores_shuf:\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b01f2a438bb2f1c73bb4594d7b96aade1401a76b920d2c9503f364300577c65b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
